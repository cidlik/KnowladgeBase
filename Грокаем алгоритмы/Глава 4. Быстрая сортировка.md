#algorithms #quicksort

### Про стратегию "разделяй и властвуй"
Автор говорит, что алгоритмы, использующие данный принцип, являются *рекурсивными*. Решение состоит из двух шагов:
1) следует определить базовый случай, это должен быть простейший случай из возможных;
2) задача делится или сокращается до тех пор, пока не будет сведена к базовому случаю.

#### Разбор задачи про деление участка
**Условие** Пусть есть участок земли прямоугольной формы. Требуется разбить этот участок земли на **одинаковые квадратные** участки таким образом, чтобы размер этих подучастков был максимально большим.
Принять, что размер участка 1680х640 м.

Используем принцип "разделяй и властвуй".
1) Определим базовый случай, самый простейший.
Самым простым является случай, когда одна сторона участка кратна другой стороне. Например, ширина участка 25х50 м:
<img src="D:\Programs\Obsidian.md\cidlik\KnowladgeBase\Грокаем алгоритмы\img\ch4_1.png" alt="ch4_1">
2) Начнем сокращать/делить участкок до тех пор, пока не дойдем до базового случая.
Разделим исходный участок на квадраты по 640 и остальное. Получится
<img src="D:\Programs\Obsidian.md\cidlik\KnowladgeBase\Грокаем алгоритмы\img\ch4_2.png" alt="ch4_2">
Останется прямоугольник 400х640. Повторяем те же действия для оставшегося участка.
* Квадрат 400, останется прямоугольник 240х400;
* Квадрат 240, останется прямоугольник 160х240;
* Квадрат 160, останется прямоугольник 160х80.
Получили базовый случай, т.к. $80 \cdot 2 = 160$.
Тогда **ответ на задачу** - можно разбить участок на квадраты по 80 м.

*Notes*:
* Данная задача сводится к поиску наибольшего общего делителя (НОД) двух целых чисел (стороны прямоугольника).
* Для данного решения используется "алгоритм Евклида" - алгоритм поиска НОД. Подробнее см. `Chapter4.py`.

### Про быструю сортировку

Быстрая сортировка - алгоритм, к которому также применим принцип "разделяй и властвуй". Определим базовый случай, когда сортировать массив проще всего. Это ситуация, когда массив или пустой, или состоит из одного элемента:
```base_case
def quicksort(l: list) -> list
	if len(l) < 2:
		return l
```

Далее массив из двух элементов. Его также несложно отсортировать. Выберем, например, элемент с индексом 0 в качестве *опорного* и сравним его с другим элементом. Если базовый больше, то поменяем элементы местами.

Далее массив из трех элементов. Например `[33, 15, 10]`. Опять выберем элемент с нулевым индексом как *опорный*. Сравним остальные элементы с опорным, те, что меньше, поставим перед ним. Получим `[15, 10] + [33] + []`. Если бы первый подмассив был бы отсортирован, то задача была бы выполнена. Но мы умеем сортировать массив из двух элементов.

Далее массив из четырех элементов. Выберем один *опорный*, тогда получим, в крайнем случае, подмассив из 3 элементов, его умеем сортировать. 

И так далее...

В данном случае используется принцип *индукции*: "умеем сортировать 2 элемента, значит сможем и 3, умеем - 3, значит сможем и 4, и т.д."

Итоговая функция быстрой сортировки может выглядеть так:
```
def quicksort(l: list) -> list
	if len(l) < 2:
		return l
	base, _ = l[0], l.pop(0)
	lesser, grater = [], []
	for el in l:
		if el < base:
			lesser.append(el)
		else:
			grater.append(el)
	return quicksort(lesser) + [base] + quicksort(grater)
```

### Заметки про скорость выполнения

Скорость быстрой сортировки не является постоянной. Она зависит от выбранного опорного элемента и неотсортированного массива в целом. Разделяют *средний* и *худший* случаи.
*Средним* можно считать обычный неотсортированный массив:
```stdin
[673, 198, 677, 837, 341, 698, 959, 426, 276, 218]
```
```stdout
[198, 218, 276, 341, 426, 673, 677, 698, 837, 959]; op_count = 22
```
*Худшим* считается случай, когда массив уже отсортирован:
```stdin
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
```
```stdout
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; op_count = 45
```

Скорость среднего случая - $O(n \cdot log(n))$. Как это определяется:
* На каждом уровне стека, так или иначе, приходится обрабатывать весь массив. Даже если мы разбиваем массив на несколько более мелких, все равно на каждом уровне стека мы будем проходить каждый их подмассивов, которые образуют целый. Это $O(n)$.
* В среднем случае (он же и лучший), мы будем бить массив пополам каждый раз. Соответственно, будет  $log(n)$ вхождений в рекурсию. Это $O(log(n))$.

В худшем случае, если массив отсортирован, то разбиения  на подмассивы не будет. Мы просто будем перебирать один подмассив, пока другой будет пустым. Это $O(n)$. Отсюда временные затраты в $O(n^{2})$.

**Вывод** Для быстрой сортировки лучше всего выбрать случайный элемент или по середине, например.